---
title: "피마 인디언 당요병 예측(로지스틱회귀)"
excerpt_separator: "<!--more-->"
categories:
  - Post Formats
tags:
   - python
   - 데이터 분석
---



# 피마 인디언 당요병 예측(로지스틱)


```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score
from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve
from sklearn.linear_model import LogisticRegression

filename ='data/diabetes.csv'
diabetes_data = pd.read_csv(filename)
diabetes_data.tail(20)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pregnancies</th>
      <th>Glucose</th>
      <th>BloodPressure</th>
      <th>SkinThickness</th>
      <th>Insulin</th>
      <th>BMI</th>
      <th>DiabetesPedigreeFunction</th>
      <th>Age</th>
      <th>Outcome</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>748</th>
      <td>3</td>
      <td>187</td>
      <td>70</td>
      <td>22</td>
      <td>200</td>
      <td>36.4</td>
      <td>0.408</td>
      <td>36</td>
      <td>1</td>
    </tr>
    <tr>
      <th>749</th>
      <td>6</td>
      <td>162</td>
      <td>62</td>
      <td>0</td>
      <td>0</td>
      <td>24.3</td>
      <td>0.178</td>
      <td>50</td>
      <td>1</td>
    </tr>
    <tr>
      <th>750</th>
      <td>4</td>
      <td>136</td>
      <td>70</td>
      <td>0</td>
      <td>0</td>
      <td>31.2</td>
      <td>1.182</td>
      <td>22</td>
      <td>1</td>
    </tr>
    <tr>
      <th>751</th>
      <td>1</td>
      <td>121</td>
      <td>78</td>
      <td>39</td>
      <td>74</td>
      <td>39.0</td>
      <td>0.261</td>
      <td>28</td>
      <td>0</td>
    </tr>
    <tr>
      <th>752</th>
      <td>3</td>
      <td>108</td>
      <td>62</td>
      <td>24</td>
      <td>0</td>
      <td>26.0</td>
      <td>0.223</td>
      <td>25</td>
      <td>0</td>
    </tr>
    <tr>
      <th>753</th>
      <td>0</td>
      <td>181</td>
      <td>88</td>
      <td>44</td>
      <td>510</td>
      <td>43.3</td>
      <td>0.222</td>
      <td>26</td>
      <td>1</td>
    </tr>
    <tr>
      <th>754</th>
      <td>8</td>
      <td>154</td>
      <td>78</td>
      <td>32</td>
      <td>0</td>
      <td>32.4</td>
      <td>0.443</td>
      <td>45</td>
      <td>1</td>
    </tr>
    <tr>
      <th>755</th>
      <td>1</td>
      <td>128</td>
      <td>88</td>
      <td>39</td>
      <td>110</td>
      <td>36.5</td>
      <td>1.057</td>
      <td>37</td>
      <td>1</td>
    </tr>
    <tr>
      <th>756</th>
      <td>7</td>
      <td>137</td>
      <td>90</td>
      <td>41</td>
      <td>0</td>
      <td>32.0</td>
      <td>0.391</td>
      <td>39</td>
      <td>0</td>
    </tr>
    <tr>
      <th>757</th>
      <td>0</td>
      <td>123</td>
      <td>72</td>
      <td>0</td>
      <td>0</td>
      <td>36.3</td>
      <td>0.258</td>
      <td>52</td>
      <td>1</td>
    </tr>
    <tr>
      <th>758</th>
      <td>1</td>
      <td>106</td>
      <td>76</td>
      <td>0</td>
      <td>0</td>
      <td>37.5</td>
      <td>0.197</td>
      <td>26</td>
      <td>0</td>
    </tr>
    <tr>
      <th>759</th>
      <td>6</td>
      <td>190</td>
      <td>92</td>
      <td>0</td>
      <td>0</td>
      <td>35.5</td>
      <td>0.278</td>
      <td>66</td>
      <td>1</td>
    </tr>
    <tr>
      <th>760</th>
      <td>2</td>
      <td>88</td>
      <td>58</td>
      <td>26</td>
      <td>16</td>
      <td>28.4</td>
      <td>0.766</td>
      <td>22</td>
      <td>0</td>
    </tr>
    <tr>
      <th>761</th>
      <td>9</td>
      <td>170</td>
      <td>74</td>
      <td>31</td>
      <td>0</td>
      <td>44.0</td>
      <td>0.403</td>
      <td>43</td>
      <td>1</td>
    </tr>
    <tr>
      <th>762</th>
      <td>9</td>
      <td>89</td>
      <td>62</td>
      <td>0</td>
      <td>0</td>
      <td>22.5</td>
      <td>0.142</td>
      <td>33</td>
      <td>0</td>
    </tr>
    <tr>
      <th>763</th>
      <td>10</td>
      <td>101</td>
      <td>76</td>
      <td>48</td>
      <td>180</td>
      <td>32.9</td>
      <td>0.171</td>
      <td>63</td>
      <td>0</td>
    </tr>
    <tr>
      <th>764</th>
      <td>2</td>
      <td>122</td>
      <td>70</td>
      <td>27</td>
      <td>0</td>
      <td>36.8</td>
      <td>0.340</td>
      <td>27</td>
      <td>0</td>
    </tr>
    <tr>
      <th>765</th>
      <td>5</td>
      <td>121</td>
      <td>72</td>
      <td>23</td>
      <td>112</td>
      <td>26.2</td>
      <td>0.245</td>
      <td>30</td>
      <td>0</td>
    </tr>
    <tr>
      <th>766</th>
      <td>1</td>
      <td>126</td>
      <td>60</td>
      <td>0</td>
      <td>0</td>
      <td>30.1</td>
      <td>0.349</td>
      <td>47</td>
      <td>1</td>
    </tr>
    <tr>
      <th>767</th>
      <td>1</td>
      <td>93</td>
      <td>70</td>
      <td>31</td>
      <td>0</td>
      <td>30.4</td>
      <td>0.315</td>
      <td>23</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



- Glucose : 포도당
- BloodPressure : 혈압
- SkinThickness : 피부 두께
- Insulin	: 인슐린
- BMI : 체질량지수
- DiabetesPedigreeFunction : 당요병 혈통 ??
- Age : 나이


```python
diabetes_data['Pregnancies'].max()
```




    17




```python
diabetes_data['Outcome'].value_counts()
```




    0    500
    1    268
    Name: Outcome, dtype: int64




```python
diabetes_data.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 768 entries, 0 to 767
    Data columns (total 9 columns):
     #   Column                    Non-Null Count  Dtype  
    ---  ------                    --------------  -----  
     0   Pregnancies               768 non-null    int64  
     1   Glucose                   768 non-null    int64  
     2   BloodPressure             768 non-null    int64  
     3   SkinThickness             768 non-null    int64  
     4   Insulin                   768 non-null    int64  
     5   BMI                       768 non-null    float64
     6   DiabetesPedigreeFunction  768 non-null    float64
     7   Age                       768 non-null    int64  
     8   Outcome                   768 non-null    int64  
    dtypes: float64(2), int64(7)
    memory usage: 54.1 KB



```python
def get_clf_eval(y_test, pred):
    confusion = confusion_matrix(y_test, pred)
    accuracy = accuracy_score(y_test, pred)
    precision = precision_score(y_test, pred)
    recall = recall_score(y_test, pred)
    f1score =f1_score(y_test, pred)
    print("오차 행렬")
    print(confusion)
    print(f' 정확도 : {accuracy} 정밀도 : {precision} 재현율 : {recall} f1score : {f1score}')
```


```python
# X값, y 레이블 로 분류

#y = diabetes_data['Outcome']
#X = diabetes_data.drop(['Outcome'], axis = 1)
X = diabetes_data.iloc[:,:-1]
y = diabetes_data.iloc[:,-1]


X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2 , random_state=156, stratify= y)

lr_clf = LogisticRegression()
lr_clf.fit(X_train, y_train)
pred = lr_clf.predict(X_test)
pred_proba =lr_clf.predict_proba(X_test)[:,1]


get_clf_eval(y_test, pred)
```

    오차 행렬
    [[88 12]
     [23 31]]
     정확도 : 0.7727272727272727 정밀도 : 0.7209302325581395 재현율 : 0.5740740740740741 f1score : 0.6391752577319588


    D:\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
    STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
    
    Increase the number of iterations (max_iter) or scale the data as shown in:
        https://scikit-learn.org/stable/modules/preprocessing.html
    Please also refer to the documentation for alternative solver options:
        https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
      n_iter_i = _check_optimize_result(



```python
def precision_recall_curve_plot(y_test , pred_proba_c1):
    precisions, recalls, thresholds = precision_recall_curve(y_test , pred_proba_c1)

    plt.figure(figsize = (8,6))
    threshold_bounduary = thresholds.shape[0]
    plt.plot(thresholds, precisions[0:threshold_bounduary],linestyle= '--', label= 'precision')
    plt.plot(thresholds, recalls[0:threshold_bounduary],label = 'reacall')

    start, end = plt.xlim()
    plt.xticks(np.round(np.arange(start,end,0.1),2))
    plt.xlabel('Threshold value');plt.ylabel('Precision and Recall Value')
    plt.legend();plt.grid()
    plt.show()

precision_recall_curve_plot(y_test,lr_clf.predict_proba(X_test)[:,1])

```


![png](\github_img\pima\output_8_0.png)
    



```python
from sklearn.metrics import roc_curve, roc_auc_score

def roc_curve_plot(y_test, pred_proba_c1):
    #임곗값에 따른 FPR, TPR값을 반환 받음
    fprs, tprs, thresholds = roc_curve(y_test, pred_proba_c1)
    #ROC Curve를 plot 곡선으로 그림
    plt.plot(fprs, tprs, label='ROC')
    #가운데 대각선 직선을 그림
    plt.plot([0,1], [0,1], 'k--', label='Random')

    #FPR X축의 Scale을 0.1 단위로 변경,  X,Y 축명 설정 등
    start, end = plt.xlim()
    plt.xticks(np.round(np.arange(start,end,0.1),2))
    plt.xlim(0,1); plt.ylim(0,1)
    plt.xlabel('FPR(1-Sensitivity)'); plt.ylabel('TPR(Recall)')
    plt.legend()
    plt.show()
roc_curve_plot(y_test, lr_clf.predict_proba(X_test)[:, 1])
```


![png](\github_img\pima\output_9_0.png)
    



```python
plt.hist(diabetes_data['Glucose'],bins = 10)
```




    (array([  5.,   0.,   4.,  32., 156., 211., 163.,  95.,  56.,  46.]),
     array([  0. ,  19.9,  39.8,  59.7,  79.6,  99.5, 119.4, 139.3, 159.2,
            179.1, 199. ]),
     <BarContainer object of 10 artists>)




![png](\github_img\pima\output_10_1.png)
    


# 스케일러 적용후


```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2 , random_state=156, stratify= y)

lr_clf = LogisticRegression()
lr_clf.fit(X_train, y_train)
pred = lr_clf.predict(X_test)
pred_proba =lr_clf.predict_proba(X_test)[:,1]

get_clf_eval(y_test, pred)
```

    오차 행렬
    [[90 10]
     [21 33]]
     정확도 : 0.7987012987012987 정밀도 : 0.7674418604651163 재현율 : 0.6111111111111112 f1score : 0.6804123711340206



```python
precision_recall_curve_plot(y_test,lr_clf.predict_proba(X_test)[:,1])
roc_curve_plot(y_test, lr_clf.predict_proba(X_test)[:, 1])
plt.hist(diabetes_data['Glucose'],bins = 10)
```


![png](\github_img\pima\output_13_0.png)
    




![png](\github_img\pima\output_13_1.png)
    





    (array([  5.,   0.,   4.,  32., 156., 211., 163.,  95.,  56.,  46.]),
     array([  0. ,  19.9,  39.8,  59.7,  79.6,  99.5, 119.4, 139.3, 159.2,
            179.1, 199. ]),
     <BarContainer object of 10 artists>)




![png](\github_img\pima\output_13_3.png)
    

