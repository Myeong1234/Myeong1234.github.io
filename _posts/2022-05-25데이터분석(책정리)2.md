---
title: "데이터 분석 이론 정리2"
toc: true
toc_sticky: true
excerpt_separator: "<!--more-->"
author_profile: true
sidebar:
  nav: "main"
categories:
  - Post Formats
tags:

  - python
  - 데이터분석
---





## 데이터 분석

데이터 전처리 과정이 완료되면 데이터 분석 과정을 진행한다. 데이터 분석은 매우 넓은 범위를 포괄하는데, 일반적으로 EDA라고 불리는 탐색적 데이터 분석을 위해 전통적인 통계 분석, 기계학습(Feature Engineering), 시각화 기법 등 다양한 방식이 활용되며 단순한 EDA를 끝으로 업무/프로젝트가 완료되는 경우도 많다.

EDA는 분석가가 데이터를 이해하고 모델링을 잘 하기 위한 필수적인 과정이다. 간혹 EDA 과정을 통한 충분한 이해와 Feature selection 없이 모델링을 바로 진행하는 경우가 있는데, 성능이 안 좋은 모델이 구축되거나 성능 개선에 많은 시간이 소요되므로 지양해야 한다.

이번 가상 케이스의 경우 EDA만을 통해 원하는 목적을 달성할 수 있으므로 EDA를 끝으로 분석 업무가 마무리 될 예정이다. 보통 이 단계쯤에서는 목적을 다시 한번 상기하는 것이 도움이 될 수 있다. 



### 일별 주요 통계

일별로 주요 지표의 흐름을 보는 것은 특정 패턴을 발견하는 데 유용하다. 특정 주나 월, 요일별로 데이터 패턴을 보거나 주요 화면의 빈도를 구함으로써 앱의 사용성 패턴에 대해 감을 잡을 수 있다.

- 일별, 요일별 데이터 빈도 및 증감 패턴
- 시간 변수와 다른 카테고리별 변수(피벗)의 상호작용

```python
# 일별 데이터 카운트 예제
df.groupby("datetime").size()

# 요일별 유니크 세션수 카운트 및 시각화 예제
s = df.groupby("datetime")['sessionid'].nunique()
s.index = s.index.dayofweek

s.plot(color='grey', kind='bar', rot=0);
plt.title("Daily Session")
plt.tight_layout() 

===============================================================
# 일별, 카테고리별 카운트 (피벗팅)
df.groupby(["datetime", "ext"]).size().unstack().dropna(axis=1)

===============================================================
# 일별 화면별 카운트 및 히트맵 시각화 예제
screens = df.groupby(["datetime", "screen"])['sessionid'].nunique().unstack().fillna(0).astype(int)
screens = screens[screens.mean().sort_values(ascending=False).index]

plt.subplots(figsize=(17,8))
sns.heatmap(screens, annot=True, fmt="d", annot_kws={"size": 15}); # we can do the same via Excel

plt.title("screen count daily")
plt.tight_layout()

================================================================
```



### 변수별 특성 (분포, 상관관계)

변수에 대한 이해를 위해 많이 사용되는 시각화 기법이 Scatter Matrix 이다. 변수별 히스토그램과 변수가 Scatter Plot을 동시에 보여주기 때문에 한눈에 데이터 특성을 파악하기 용이하다. 이외 Box-plot, Bar Plot 등 다양한 시각화 기법이 이용된다.

- Histogram
- Scatter Plot
- Box Plot
- Bar Plot

```
# Scatter Matrix 를 통해 분포 및 변수간 상관관계 시각화 예제
from pandas.tools.plotting import scatter_matrix

scatter_matrix(df_by_user, figsize=(10, 10));
plt.tight_layout()

#  상관지수 확인
df_by_user.corr()
```

### 구간별 전환율

전환율을 구하기 위한 수식은 간단하다. **분자 / 분모 \* 100** 수식을 이용해 간단히 전환%를 산출할 수 있다.

- 주요 구간 설정
- 전환율 수식 적용

```python
# 구간별 전환수 
conver_cnt = screens.mean().apply(lambda x: int(x)).sort_values(ascending=False)

# 구간별 전환율 및 시각화 예제
conver_rt = [conver_cnt[i + 1] / (conver_cnt[i] * 1.0) * 100 for i in range(len(conver_cnt)) if i < 6]

fun_label = [conver_cnt.index[k] + " -> " + conver_cnt.index[k + 1] for k, v in enumerate(conver_cnt.index) if k < 6]

pd.Series(conver_rt, index=fun_label).plot(kind='bar', color = 'darkblue', rot=20, figsize=(10,7), fontsize=13)

plt.title("Conver Rate")
plt.tight_layout()

# 구간별 전환율 및 이탈율 비교 시각화 예제
conv_rt_tb = pd.Series(conver_rt, index=fun_label).to_frame()

conv_rt_tb.index.name = 'Funnel'
conv_rt_tb.columns = ['conver_rt']
conv_rt_tb['churn_rt'] = 100 - conv_rt_tb['conver_rt']

sns.heatmap(conv_rt_tb, annot=True, annot_kws={"size": 15});
plt.tight_layout()
```



## 클러스터 별 전환율 차이

전체 유저를 대상으로 전환율을 구할 경우 큰 Implication 을 얻기 어렵다. 최대한 쪼개서 볼수록 많은 인사이트를 얻을 수 있으며, 유저를 분류할 때 많이 쓰이는 기법이 클러스터링이다.

- 클러스터링을 위한 주요 변수 설정 (필요시 PCA로 차원 축소)
- K-Means 알고리즘 적용후 그룹핑
- 그룹별 대푯값 및 시각화 등을 통해 탐색
- 여러 요인을 카테고리 단으로 묶는 요인분석(Factor Analysis)과 목적이 다름에 유의

```
# K-Means 이용한 클러스터링 예제
from sklearn.cluster import KMeans

df_ext_mat = df_ext.as_matrix()
km = KMeans(n_clusters = 4).fit(df_ext_mat)
labels = km.labels_

# group 변수 생성
df_ext['group'] = labels

# 숫자 to 그룹명 변경
group_name = {0: 'gr_hwp',
              1: 'gr_pdf',
              2: 'gr_xls',
              3: 'gr_doc'}

df_ext['group'] = df_ext['group'].replace(group_name)

# 그룹별 전환율 함수 생성
def conv_rt_by_grp(gr):
    df_gr_screen = df_cluster[df_cluster['group'] == gr]\
                     .groupby(["datetime", "screen"])['sessionid']\
                     .nunique().unstack().fillna(0).astype(int)

    conver_cnt = df_gr_screen.mean().apply(lambda x: int(x)).sort_values(ascending=False)
    conver_rt = [conver_cnt[i + 1] / (conver_cnt[i] * 1.0) * 100 for i in range(len(conver_cnt)) if i < 6]
    conver_rt = pd.Series(conver_rt, index=fun_label).fillna(0)    
    return conver_rt

# 그룹별 전환율 산출
conv_rt_pdf = conv_rt_by_grp('gr_pdf')
conv_rt_doc = conv_rt_by_grp('gr_doc')
conv_rt_xls = conv_rt_by_grp('gr_xls')
conv_rt_hwp = conv_rt_by_grp('gr_hwp')

# 가중치 부여
weights = [1, 1.3, 1.5, 2, 2.1, 2.2]

def weight_avg(gr):
    w = (gr.values * weights).sum() / len(gr)
    return w

# 가중치 함수 적용
gr_pdf_w = weight_avg(conv_rt_pdf)
gr_doc_w = weight_avg(conv_rt_doc)
gr_xls_w = weight_avg(conv_rt_xls)
gr_hwp_w = weight_avg(conv_rt_hwp)

# 데이터프레임으로 변환
zip([gr_pdf_avg, gr_doc_avg, gr_xls_avg, gr_hwp_avg], [gr_pdf_w, gr_doc_w, gr_xls_w, gr_hwp_w])

avg_df = pd.DataFrame(list(zip([gr_pdf_avg, gr_doc_avg, gr_xls_avg, gr_hwp_avg],\
                                   [gr_pdf_w, gr_doc_w, gr_xls_w, gr_hwp_w])), \
                                   columns = ['mean', 'wg_mean'],\
                                   index = ['gr_pdf', 'gr_doc', 'gr_xls', 'gr_hwp'])

# 가중치 부여 결과 시각화
avg_df.plot(kind='barh')
plt.tight_layout()
```



