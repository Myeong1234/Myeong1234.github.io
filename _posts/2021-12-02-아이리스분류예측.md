---
title: "iris 분류 예측"
toc: true
toc_sticky: true
excerpt_separator: "<!--more-->"
author_profile: true
sidebar:
  nav: "main"
categories:
  - Post Formats
tags:
   - python
   - 데이터 분석
---



# 아이리스 분류 예측


```python
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from sklearn.preprocessing import LabelEncoder

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
```


```python
df = pd.read_csv('./dataset/iris.csv',names = ["sepal_length", "sepal_width","petal_length", "petal_width","species"])
print(df)
```

         sepal_length  sepal_width  petal_length  petal_width         species
    0             5.1          3.5           1.4          0.2     Iris-setosa
    1             4.9          3.0           1.4          0.2     Iris-setosa
    2             4.7          3.2           1.3          0.2     Iris-setosa
    3             4.6          3.1           1.5          0.2     Iris-setosa
    4             5.0          3.6           1.4          0.2     Iris-setosa
    ..            ...          ...           ...          ...             ...
    145           6.7          3.0           5.2          2.3  Iris-virginica
    146           6.3          2.5           5.0          1.9  Iris-virginica
    147           6.5          3.0           5.2          2.0  Iris-virginica
    148           6.2          3.4           5.4          2.3  Iris-virginica
    149           5.9          3.0           5.1          1.8  Iris-virginica
    
    [150 rows x 5 columns]


# pairplot 확인


```python
sns.pairplot(df, hue='species')
plt.show()
```


![png](/github_img/output_4_0.png)
    


# 같은 결과를 받기 위해 시드 고정


```python
np.random.seed(3)
tf.random.set_seed(3)
```


```python
#데이터 분류
dataset = df.values
X = dataset[:,0:4].astype(float)
Y_obj = dataset[:,4]

#문자열 숫자로 변환
e = LabelEncoder()
e.fit(Y_obj)
Y = e.transform(Y_obj)
Y_encoded = tf.keras.utils.to_categorical(Y)

```


```python
#모델 생성
model = Sequential()
model.add(Dense(16, input_dim = 4, activation ='relu'))
model.add(Dense(3, activation='softmax'))
```


```python
model.compile(loss = 'categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])
```


```python
model.fit(X,Y_encoded, epochs=50, batch_size =1)
print("\n Accuracy: %.4f"% (model.evaluate(X,Y_encoded)[1]))
```

    Epoch 1/50
    150/150 [==============================] - 0s 1ms/step - loss: 1.2472 - accuracy: 0.3467
    Epoch 2/50
    150/150 [==============================] - 0s 935us/step - loss: 0.9901 - accuracy: 0.4000
    Epoch 3/50
    150/150 [==============================] - 0s 959us/step - loss: 0.7890 - accuracy: 0.5333
    Epoch 4/50
    150/150 [==============================] - 0s 992us/step - loss: 0.6356 - accuracy: 0.8133
    Epoch 5/50
    150/150 [==============================] - 0s 972us/step - loss: 0.5382 - accuracy: 0.8533
    Epoch 6/50
    150/150 [==============================] - 0s 955us/step - loss: 0.4621 - accuracy: 0.9133
    Epoch 7/50
    150/150 [==============================] - 0s 942us/step - loss: 0.4111 - accuracy: 0.9333
    Epoch 8/50
    150/150 [==============================] - 0s 922us/step - loss: 0.3830 - accuracy: 0.9267
    Epoch 9/50
    150/150 [==============================] - 0s 932us/step - loss: 0.3530 - accuracy: 0.9400
    Epoch 10/50
    150/150 [==============================] - ETA: 0s - loss: 0.3132 - accuracy: 0.97 - 0s 932us/step - loss: 0.3266 - accuracy: 0.9667
    Epoch 11/50
    150/150 [==============================] - 0s 929us/step - loss: 0.2992 - accuracy: 0.9467
    Epoch 12/50
    150/150 [==============================] - 0s 962us/step - loss: 0.2773 - accuracy: 0.9467
    Epoch 13/50
    150/150 [==============================] - 0s 1ms/step - loss: 0.2690 - accuracy: 0.9600
    Epoch 14/50
    150/150 [==============================] - 0s 1ms/step - loss: 0.2479 - accuracy: 0.9733
    Epoch 15/50
    150/150 [==============================] - 0s 982us/step - loss: 0.2328 - accuracy: 0.9600
    Epoch 16/50
    150/150 [==============================] - 0s 929us/step - loss: 0.2234 - accuracy: 0.9600
    Epoch 17/50
    150/150 [==============================] - 0s 945us/step - loss: 0.2111 - accuracy: 0.9600
    Epoch 18/50
    150/150 [==============================] - 0s 1ms/step - loss: 0.2099 - accuracy: 0.9667: 0s - loss: 0.2383 - accuracy: 0.
    Epoch 19/50
    150/150 [==============================] - 0s 982us/step - loss: 0.1903 - accuracy: 0.9667
    Epoch 20/50
    150/150 [==============================] - 0s 935us/step - loss: 0.1822 - accuracy: 0.9667
    Epoch 21/50
    150/150 [==============================] - 0s 922us/step - loss: 0.1746 - accuracy: 0.9733
    Epoch 22/50
    150/150 [==============================] - 0s 949us/step - loss: 0.1716 - accuracy: 0.9600
    Epoch 23/50
    150/150 [==============================] - 0s 1ms/step - loss: 0.1609 - accuracy: 0.9733
    Epoch 24/50
    150/150 [==============================] - 0s 942us/step - loss: 0.1587 - accuracy: 0.9733
    Epoch 25/50
    150/150 [==============================] - 0s 939us/step - loss: 0.1494 - accuracy: 0.9733
    Epoch 26/50
    150/150 [==============================] - 0s 962us/step - loss: 0.1418 - accuracy: 0.9800
    Epoch 27/50
    150/150 [==============================] - ETA: 0s - loss: 0.1331 - accuracy: 0.98 - 0s 949us/step - loss: 0.1439 - accuracy: 0.9800
    Epoch 28/50
    150/150 [==============================] - 0s 975us/step - loss: 0.1227 - accuracy: 0.9933
    Epoch 29/50
    150/150 [==============================] - 0s 949us/step - loss: 0.1351 - accuracy: 0.9733
    Epoch 30/50
    150/150 [==============================] - 0s 1ms/step - loss: 0.1318 - accuracy: 0.9667
    Epoch 31/50
    150/150 [==============================] - 0s 1ms/step - loss: 0.1255 - accuracy: 0.9800
    Epoch 32/50
    150/150 [==============================] - 0s 1ms/step - loss: 0.1249 - accuracy: 0.9600
    Epoch 33/50
    150/150 [==============================] - 0s 1ms/step - loss: 0.1175 - accuracy: 0.9733
    Epoch 34/50
    150/150 [==============================] - 0s 1ms/step - loss: 0.1163 - accuracy: 0.9600
    Epoch 35/50
    150/150 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.9667
    Epoch 36/50
    150/150 [==============================] - 0s 915us/step - loss: 0.1134 - accuracy: 0.9667
    Epoch 37/50
    150/150 [==============================] - 0s 916us/step - loss: 0.1050 - accuracy: 0.9667
    Epoch 38/50
    150/150 [==============================] - 0s 882us/step - loss: 0.1101 - accuracy: 0.9667
    Epoch 39/50
    150/150 [==============================] - 0s 945us/step - loss: 0.1014 - accuracy: 0.9800
    Epoch 40/50
    150/150 [==============================] - 0s 915us/step - loss: 0.1102 - accuracy: 0.9600
    Epoch 41/50
    150/150 [==============================] - 0s 886us/step - loss: 0.1002 - accuracy: 0.9733
    Epoch 42/50
    150/150 [==============================] - 0s 1ms/step - loss: 0.1025 - accuracy: 0.9800: 0s - loss: 0.0992 - accuracy: 
    Epoch 43/50
    150/150 [==============================] - 0s 1ms/step - loss: 0.0992 - accuracy: 0.9733
    Epoch 44/50
    150/150 [==============================] - 0s 1ms/step - loss: 0.0971 - accuracy: 0.9733
    Epoch 45/50
    150/150 [==============================] - 0s 1ms/step - loss: 0.1017 - accuracy: 0.9533
    Epoch 46/50
    150/150 [==============================] - 0s 959us/step - loss: 0.0954 - accuracy: 0.9800
    Epoch 47/50
    150/150 [==============================] - 0s 955us/step - loss: 0.0971 - accuracy: 0.9600
    Epoch 48/50
    150/150 [==============================] - 0s 1ms/step - loss: 0.0910 - accuracy: 0.9600
    Epoch 49/50
    150/150 [==============================] - 0s 1ms/step - loss: 0.0963 - accuracy: 0.9667
    Epoch 50/50
    150/150 [==============================] - 0s 1ms/step - loss: 0.0950 - accuracy: 0.9533
    5/5 [==============================] - 0s 1ms/step - loss: 0.0857 - accuracy: 0.9733
    
     Accuracy: 0.9733



```python

```
